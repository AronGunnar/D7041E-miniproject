{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcb8018-ceca-435b-806f-fcf5a8aad5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: iris\n",
      "KNN Accuracy for iris: 100.00%\n",
      "K-Means Accuracy for iris: 88.67%\n",
      "===\n",
      "Processing dataset: glass\n",
      "KNN Accuracy for glass: 74.42%\n",
      "K-Means Accuracy for glass: 49.53%\n",
      "===\n",
      "Processing dataset: balance-scale\n",
      "KNN Accuracy for balance-scale: 78.40%\n",
      "K-Means Accuracy for balance-scale: 64.16%\n",
      "===\n",
      "Processing dataset: heart-cleveland\n",
      "KNN Accuracy for heart-cleveland: 48.33%\n",
      "K-Means Accuracy for heart-cleveland: 53.87%\n",
      "===\n",
      "Processing dataset: ecoli\n",
      "KNN Accuracy for ecoli: 86.76%\n",
      "K-Means Accuracy for ecoli: 75.00%\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def import_dataset(name):\n",
    "    datasets = {\n",
    "        \"iris\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "        \"glass\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data\",\n",
    "        \"balance-scale\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data\",\n",
    "        \"heart-cleveland\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\",\n",
    "        \"ecoli\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/ecoli/ecoli.data\"\n",
    "    }\n",
    "    \n",
    "    # Load the datasets\n",
    "    url = datasets[name]\n",
    "    if name == \"iris\":\n",
    "        df = pd.read_csv(url, header=None)\n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = pd.Categorical(df.iloc[:, -1]).codes\n",
    "    elif name == \"glass\":\n",
    "        df = pd.read_csv(url, header=None)\n",
    "        X = df.iloc[:, 1:-1].values\n",
    "        y = df.iloc[:, -1].values\n",
    "    elif name == \"balance-scale\":\n",
    "        df = pd.read_csv(url, header=None)\n",
    "        X = df.iloc[:, 1:].values\n",
    "        y = pd.Categorical(df.iloc[:, 0]).codes\n",
    "    elif name == \"heart-cleveland\":\n",
    "        df = pd.read_csv(url, header=None, na_values=\"?\")\n",
    "        df.dropna(inplace=True)\n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = pd.Categorical(df.iloc[:, -1]).codes\n",
    "    elif name == \"ecoli\":\n",
    "        df = pd.read_csv(url, sep=r'\\s+', header=None)\n",
    "        X = df.iloc[:, 1:-1].values\n",
    "        y = pd.Categorical(df.iloc[:, -1]).codes\n",
    "    return X, y\n",
    "\n",
    "# Apply KNN and K-Means to multiple datasets\n",
    "datasets = [\"iris\", \"glass\", \"balance-scale\", \"heart-cleveland\", \"ecoli\"]\n",
    "k = 3\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Processing dataset: {dataset}\")\n",
    "    X, y = import_dataset(dataset)\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # KNN Classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_predictions = knn.predict(X_test)\n",
    "    knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "    print(f\"KNN Accuracy for {dataset}: {knn_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # K-Means Clustering\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "\n",
    "    # Map clusters to true labels for accuracy calculation\n",
    "    cluster_mapping = {}\n",
    "    for cluster_id in range(k):\n",
    "        cluster_points = [y[i] for i in range(len(y)) if kmeans_labels[i] == cluster_id]\n",
    "        if cluster_points:\n",
    "            most_common_label = pd.Series(cluster_points).mode()[0]\n",
    "            cluster_mapping[cluster_id] = most_common_label\n",
    "    kmeans_predictions = [cluster_mapping[label] for label in kmeans_labels]\n",
    "    kmeans_accuracy = accuracy_score(y, kmeans_predictions)\n",
    "    print(f\"K-Means Accuracy for {dataset}: {kmeans_accuracy * 100:.2f}%\")\n",
    "    print(\"===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781abe53-f059-4c45-bcd4-f782265859bc",
   "metadata": {},
   "source": [
    "## Q1: Names of all group members"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0ee61-d6c4-49e6-9d0b-e1da1ccfb940",
   "metadata": {},
   "source": [
    "Oscar Borén, oscbor-9@student.ltu.se  \n",
    "Alexander Pettersson, aleepe-1@student.ltu.se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea909584-72d1-4d88-b16a-024bf4da091e",
   "metadata": {},
   "source": [
    "## Q2: Clear specification of the addressed grading criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1719a-b636-444b-9de8-cb30c18b84f5",
   "metadata": {},
   "source": [
    "\"For grade 3: Develop 1 unsupervised and 1 supervised classification model for 5 datasets of your choice from 121 UCI datasets. Report accuracy results\"\n",
    "\n",
    "Supervised: K-Nearest Neighbors\n",
    "Unsupervised: K-Means Clustering\n",
    "\n",
    "Tested on iris, glass, balance-scale, heart-cleveland, and ecoli. For accuracy, see printout above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae53ed0-1c79-4199-857c-eb8cb68b1173",
   "metadata": {},
   "source": [
    "## Q3: Description of the datasets used in the miniproject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8df81-cdc4-4a54-a80b-9f6e9e9e1a46",
   "metadata": {},
   "source": [
    "====== 1. Iris Dataset ======  \n",
    "A dataset often used in pattern recognition. It contains measurements of iris flowers from three different species.  \n",
    "  \n",
    "Input: Sepal length, sepal width, petal length, petal width.  \n",
    "Classes: Setosa, versicolour, virginica.  \n",
    "Size: 150 instances, 4 features.  \n",
    "Majority percantage: 33.3%.\n",
    "\n",
    "  \n",
    "====== 2. Glass Identification Dataset ======  \n",
    "Used for studying classification of glass types based on chemical composition. The goal here is to predict the type of glass based on its oxide content.  \n",
    "\n",
    "Input: Refractive index, various oxide contents (e.g., sodium, magnesium, etc.).  \n",
    "Classes: Building windows (float-processed), building windows (non-float-processed), vehicle windows (float-processed), vehicle windows (non-float-processed), containers, tableware, headlamps.  \n",
    "Size: 214 patterns, 9 features.  \n",
    "Majority percantage: 35.5%.\n",
    "\n",
    "  \n",
    "====== 3. Balance Scale Dataset ======  \n",
    "Simulated data for balance scale weight and distance measurements. Used to predict the tilt direction of the scale.  \n",
    "\n",
    "Input: Left weight, left distance, right weight, right distance.  \n",
    "Classes: L (left tilt), B (balanced), R (right tilt).  \n",
    "Size: 625 patterns, 4 features.  \n",
    "Majority percantage: 46.1%.\n",
    "\n",
    "  \n",
    "====== 4. Heart Disease (Cleveland) Dataset ======  \n",
    "A dataset designed to predict the presence of heart disease based on patient attributes. It contains clinical data and diagnostic results.  \n",
    "\n",
    "Input: Age, sex, chest pain type, resting blood pressure, serum cholesterol, fasting blood sugar, resting ECG, maximum heart rate, etc.  \n",
    "Classes: Diagnosis of heart disease (0: Absence, 1–4: Severity).  \n",
    "Size: 303 patterns, 13 features.  \n",
    "Majority percantage: 54.1%\n",
    "\n",
    "  \n",
    "====== 5. E. Coli Dataset ======  \n",
    "A dataset for protein localization sites in cells of E. coli. It predicts the location of proteins based on features.  \n",
    "\n",
    "Input: Sequence-based properties like McGeoch's signal sequence or von Heijne’s signal sequence scores.-  \n",
    "Classes: Cytoplasm, inner membrane (no signal sequence), periplasm, outer membrane, etc.  \n",
    "Size: 336 patterns, 7 features.  \n",
    "Majority percantage: 42.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa775cf-437f-444f-ae29-421393ba8c8d",
   "metadata": {},
   "source": [
    "## Q4: Description of the models used in the miniproject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95570cb3-ff2f-4810-8ecc-1b406320657c",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors:  \n",
    "    * Hyperparams.: n_clusters.  \n",
    "    * Search Space: n_clusters set to 3, specifying the number of clusters to form.  \n",
    "\n",
    "K-Means:  \n",
    "    * Hyperparams.: n_neighbors and random_state.  \n",
    "    * Search Space: n_neighbors is set to 3, which detirmines the number of nearest neighbors considered for classification.  \n",
    "                    random_state fixed at 42 to ensure reproducibility.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31d88e-8552-48c4-8659-b32017ec2a43",
   "metadata": {},
   "source": [
    "## Q5: Description of the experimental methodology (datasets' splits, cross-validation, performance metricsetc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9d561a-2c5a-43fd-9533-1aae9c17600d",
   "metadata": {},
   "source": [
    "Dataset Splits: Datasets are split into training and testing subsets using an 80-20 split.\n",
    "\n",
    "Cross-Validation: No real cross-validation was performed. Instead, the performance were assessed using a single train-test split. Could use k-fold cross-validation for better evaluation.\n",
    "\n",
    "Performance Metrics:  \n",
    "    * KNN: Accuracy Score was calculated as a ratio of correct labels to the total number of predictions.  \n",
    "    * K-Means: K-Means clusters were mapped to the most common true label in each cluster to approximate classification accuracy.  \n",
    "               Accuracy Score were once again used as the mapped predictions were compared with true labels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a2e88-3850-4e8c-be08-fb16f2262428",
   "metadata": {},
   "source": [
    "## Q6: Description of the experimental results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eec2cd-0bb1-41c2-844f-3b0e0ca9f2c6",
   "metadata": {},
   "source": [
    "KNN outperformed K-Means in the majority of datasets and we think that's partly dues to the supervised nature. From K-Means' results we think that it performs better on simpler datasets like iris while suffers on more complex ones like glass and heart-cleveland. K-Means might just be less suited for this type of datasets compared to KNN though. One thing that potentially could've improved performance is a change in n_clusters where a fixed value of 3 might not have been optimal. Obviously, cross-validation could also have a positive impact on the accuracy compared to the train-test split we used. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca63155-d6f0-4d41-a393-c094b84b9d83",
   "metadata": {},
   "source": [
    "## Q7: Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e01ac70-cc1a-412b-b878-1b305af79987",
   "metadata": {},
   "source": [
    "The results show that KNN gives better accuracy on most of the chosen datasets than K-Means. This is probably because it uses labeled data, which is better in scenarios with well-separated class boundaries (e.g. 100% accuracy on Iris). However, KNN doesn't perform as well when the data is noisy or overlapping, as seen in its lower accuracy on Heart-Cleveland (48.33%). K-Means showed varying performance, performing well when clusters aligned with true labels (e.g. 88.67% on Iris) but struggling with overlapping classes (e.g. 49.53% on Glass). Overall, KNN is better suited for tasks requiring precise classification, while K-Means is useful for when labels are unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801ff7a-b786-4e8a-8c8c-ede560865ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
